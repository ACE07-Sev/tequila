{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-qubit classifier with data re-uploading tutorial\n",
    "\n",
    "This tutorial shows:\n",
    "- How to construct a fidelity cost function for an optimization problem\n",
    "- How to construct a quantum classifier with one qubit\n",
    "\n",
    "Based on [Data re-uploading for a universal quantum classifier](https://quantum-journal.org/papers/q-2020-02-06-226/), A. P√©rez-Salinas, A. Cervera-Lierta, E. Gil-Fuster, and J. I. Latorre, *Quantum **4**, 226 (2020)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tequila as tq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Single-qubit operations are just rotations on the Bloch sphere. A collection of single-qubit rotations can be reduced to a single one by combining their angles: you can always move from one point to another on the Bloch sphere with a single operation. \n",
    "\n",
    "Because of this property, a single-qubit classifier with simple parameterized rotations can not treat complex data. Even if it succeeds to classify one data point, it will probably misclassify the others since rotational angles have been only adapted to one particular point. To circumvent this limitation one can introduce the data points into these angles, so each rotation will be data point-dependent. This methodology is called data re-uploading and it can be shown that a single-qubit classifier can be universal using this technique.\n",
    "\n",
    "The strategy to train this single-qubit classifier is the following. Given a problem with ùëõn classes, we choose ùëõn vectors on the Bloch sphere. Then, we train the classifier by constructing a cost function that adds penalties if the final state of the classifier is far from the target state that corresponds to its class.\n",
    "\n",
    "The single-qubit classifier circuit is divided into layers. Each layer comprises single-qubit rotations that encode a data training point and parameters to be optimized. $$ L\\left(\\vec{x};\\vec{\\theta}_{i}\\right) = U\\left(\\vec{x}\\right)U\\left(\\vec{\\theta}_{i}\\right) $$\n",
    "\n",
    "By considering more layers, the final state of the classifier will have a richer structure in terms of the data point $\\vec{x}$.\n",
    "\n",
    "$$ \\mathcal{U}_{class}\\left(\\vec{x};\\vec{\\theta}_{1},\\vec{\\theta}_{2},...,\\vec{\\theta}_{l}\\right) = L\\left(\\vec{x};\\vec{\\theta}_{1}\\right)L\\left(\\vec{x};\\vec{\\theta}_{2}\\right)\\cdots L\\left(\\vec{x};\\vec{\\theta}_{l}\\right)$$\n",
    "\n",
    "We will run a $\\mathcal{U}_{class}$ for each training point $\\vec{x}$, but the parameters $\\vec{\\theta}$ are the same. These are the variables to be optimized classically through the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model that we would like to classify. Let's start with a simple model with two classes: a circle of radius $r =\\sqrt{2/\\pi}$ centered at (0,0). Data points will be distributed in a square of length 2 centered at (0,0). The particular choice of the circle radius implies that a random classification will have a $\\sim 50$% accuracy.\n",
    "\n",
    "`circle` function will have two parts:\n",
    "- `random = True`: generate and label random points according to their position inside or outside the circle (used for training)\n",
    "- `random = False`: computes the label of a given point `x_input` (used for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def circle(samples = False, random = True, x_input = False, center=[0.0, 0.0], radius=np.sqrt(2 / np.pi)):   \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samples (int): number of samples to generate\n",
    "        random = True: generates and labels sample random points\n",
    "        random = False: labels x_input point\n",
    "        x_input (array[tuple]): given point to be labeled if random = False\n",
    "        center (tuple): center of the circle\n",
    "        radius (float): radius of the circle\n",
    "\n",
    "    Returns:\n",
    "        if random = True:\n",
    "            xvals (array[tuple]): data points coordinates \n",
    "            yvals (array[int]): corresponding data labels\n",
    "        if random = False:\n",
    "            y (int): label of x_input point\n",
    "    \"\"\"\n",
    "    xvals, yvals = [], []\n",
    "\n",
    "    if random == True:\n",
    "        for i in range(samples):\n",
    "            x = 2 * (np.random.rand(2)) - 1\n",
    "            y = 0\n",
    "            if np.linalg.norm(x - center) < radius:\n",
    "                y = 1\n",
    "            xvals.append(x)\n",
    "            yvals.append(y)        \n",
    "        return np.array(xvals), np.array(yvals)\n",
    "    \n",
    "    if random == False:\n",
    "        y = 0\n",
    "        if np.linalg.norm(x_input - center) < radius:\n",
    "            y = 1\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target states\n",
    "\n",
    "Next step is to fix the classes states. The classifier will be trained to return these states depending on the data point. To reduce the uncertanty, target states should be as much distanced as possible. With a single qubit, that means to choose points in the Bloch sphere as much separated as possible.\n",
    "For a two-class problem, an easy choice is $|0\\rangle$ and $|1\\rangle$ states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |0> : points inside the circle\n",
    "# |1> : points outside the circle\n",
    "def targ_wfn(y, nclass):\n",
    "    \"\"\"\n",
    "    Arg:\n",
    "        - y (int): class label\n",
    "        - nclass: number of classes\n",
    "    Returns:\n",
    "        - wfn: wavefunction of the target state\n",
    "    \"\"\"\n",
    "    if nclass == 2:\n",
    "        if y==0:\n",
    "            wfn = tq.QubitWaveFunction.from_array(np.asarray([1,0]))\n",
    "        if y==1:\n",
    "            wfn = tq.QubitWaveFunction.from_array(np.asarray([0,1]))\n",
    "    else:\n",
    "        raise Exception(\"nclass = {} is not considered\".format(nclass))\n",
    "    return wfn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-qubit classifier circuit\n",
    "\n",
    "The single-qubit classifier has a layer structure, i.e. we have to decide how to design one layer and then how many layers we would like to consider. \n",
    "We will consider the following structure: each layer is a collection of rotational gates which angles are a linear function of a data point with the free parameters to be optimized. In particular,\n",
    "$$L\\left(\\vec{x};\\vec{\\theta}_{i}\\right) = R_{z}\\left(x^{2}+\\theta_{i}^{2}\\right) R_{y}\\left(x^{1}+\\theta_{i}^{1}\\right).$$\n",
    "\n",
    "Then, each layer adds 2 parameters to be optimized. The data points $(x^1,x^2)$ are re-uploaded in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single-qubit quantum classifier circuit\n",
    "def qcircuit(xval, param):\n",
    "    \"\"\"\n",
    "    Arg:\n",
    "        - xval (array[tuple]): data point\n",
    "        - param (dict): parameters dictionary\n",
    "    Returns:\n",
    "        - qc: quantum circuit\n",
    "    \"\"\"\n",
    "    layers = int((len(param))/2) # 2 parameters/layer\n",
    "    # initialize the circuit \n",
    "    qc = tq.gates.Rz(0.0,0)\n",
    "    for p in range(0,2*layers-1):\n",
    "        # add layers to the circuit\n",
    "        qc += tq.gates.Ry(xval[0] + param[p],0) + tq.gates.Rz(xval[1] + param[p+1],0) \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "The cost function for this quantum classifier model will be constructed from the fidelity of the classifier final state respect to the target state of its corresponding class. It will penalize that the output state is far from its label state.\n",
    "\n",
    "First, we define the fidelity between two states as an objective (see State Preparation Tutorial). Then, we construct the simplest cost function of this kind: average of squared infidelities for all training points $M$: $$ \\chi^2 = \\sum_{i=1}^{M}\\left(1-|\\langle\\psi_{target}|\\psi_{circuit}\\rangle|^2\\right)^2$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fidelity objective\n",
    "def fid(wfn_targ, qc):\n",
    "    \"\"\"\n",
    "    Arg:\n",
    "        - wfn_targ: target wavefunction\n",
    "        - qc : quantum circuit \n",
    "    Returns:\n",
    "        - O: objective\n",
    "    \"\"\"  \n",
    "    rho_targ =  tq.paulis.Projector(wfn=wfn_targ)\n",
    "    O = tq.Objective.ExpectationValue(U=qc, H=rho_targ)\n",
    "    # fidelity = tq.simulate(O)\n",
    "    return O \n",
    "\n",
    "# cost function: sum of all infidelities for each data point respect the label state\n",
    "def cost(x, y, param, nclass):\n",
    "    \"\"\"\n",
    "    Arg:\n",
    "        - x (array[tuple]): training points\n",
    "        - y (array[int]): labels of training points\n",
    "        - param (dict): parameters dictionary\n",
    "        - nclass (int): number of classes\n",
    "    Returns:\n",
    "        - loss/ len(x): loss objective\n",
    "    \"\"\"  \n",
    "    loss = 0.0\n",
    "    # M = len(y): number of training points\n",
    "    for i in range(len(y)):\n",
    "        \n",
    "        # state generated by the classifier\n",
    "        qc = qcircuit(x[i], param)\n",
    "        # fidelity objective respect to the label state\n",
    "        f = fid(targ_wfn(y[i],nclass), qc)\n",
    "        \n",
    "        loss = loss + (1 - f)**2\n",
    "        \n",
    "    return loss / len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We have now all the ingredients to train a single-qubit classifier with data re-uploading.  \n",
    "If a gradient based optimization is chosen for this type of optimization problems, numerical gradients are adviced since analytical ones become quite expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 3\n",
    "nclass = 2\n",
    "training_set = 400\n",
    "\n",
    "# generate the training set and its corresponding labels\n",
    "xdata, ydata = circle(training_set)\n",
    "\n",
    "# generate the variational parameters\n",
    "param = [tq.Variable(name='th_{}'.format(i)) for i in range(0,2*layers)]\n",
    "\n",
    "# initialize the variational parameters\n",
    "# note that due to the random initialization the result can be different from time to time\n",
    "# With gradient based optimization you might get stuck\n",
    "inval = {key : random.uniform(0, 2*np.pi) for key in param}\n",
    "\n",
    "grad = '2-point' # numerical gradient (= None: analytical gradient)\n",
    "mthd = 'rmsprop' # scipy minimization method\n",
    "mthd_opt = {'eps':1.e-4} # method options (that's the stepsize for the gradients)\n",
    "\n",
    "obj = cost(xdata, ydata, param, nclass) # objective to be optimized: cost function\n",
    "\n",
    "t0 = time.time()\n",
    "# depending on the optimizer this will take a while\n",
    "test = tq.minimize(objective=obj, initial_values=inval, method = mthd,\n",
    "                                   gradient = grad, method_options = mthd_opt, silent=False)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss = \", test.energy)\n",
    "print(\"method: \", mthd)\n",
    "print(\"method parameters: \", mthd_opt)\n",
    "print(\"execution time = \", (t1-t0)/60, \" min\")\n",
    "\n",
    "print(test.history.plot('energies', label='loss'))\n",
    "print(test.history.plot('angles', label=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Once trained, we have the optimal parameters for the classifier stored in `test.angles`. We run again the classifier with the test data set and with these parameters fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = 1000\n",
    "\n",
    "# initialize\n",
    "xval_test, yval_test, yval_rand, yval_real = [], [], [], []\n",
    "suc = 0 # success\n",
    "suc_rand = 0 # random success\n",
    "\n",
    "for i in range(test_set):\n",
    "    \n",
    "    # random test point\n",
    "    x = 2 * (np.random.rand(2)) - 1\n",
    "    \n",
    "    # state generated by the trained classifier\n",
    "    qc = qcircuit(x, param)\n",
    "    wfn_qc = tq.simulate(qc, variables=test.angles) \n",
    "        \n",
    "    if nclass == 2:\n",
    "        \n",
    "        # compute the fidelity respect to one of the label states, the |0>\n",
    "        f = abs(wfn_qc.inner(targ_wfn(0,nclass)))**2\n",
    "\n",
    "        y = 1\n",
    "        # if fidelity is >= 0.5, we conclude that this state belongs to |0> class\n",
    "        # (|1> class otherwise)\n",
    "        if f >= 0.5:\n",
    "            y = 0\n",
    "            \n",
    "        # check the real class of the data point\n",
    "        y_real = circle(random=False, x_input=x)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"nclass = {} is not considered\".format(nclass))\n",
    "    \n",
    "    # compute success rate \n",
    "    if y == y_real:\n",
    "        suc = suc + 1\n",
    "        \n",
    "    # compute random success rate \n",
    "    yrand = np.random.randint(0, nclass-1)\n",
    "    if yrand == y_real:\n",
    "        suc_rand = suc_rand + 1\n",
    "        \n",
    "    xval_test.append(x)\n",
    "    yval_test.append(y)\n",
    "    yval_real.append(y_real)\n",
    "    \n",
    "print(\"success %: \", 100*suc/test_set,\"%\")\n",
    "print(\"random success %: \", 100*suc_rand/test_set,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x, y, nclass, fig=None, ax=None):\n",
    "    \"\"\"\n",
    "    Arg:\n",
    "        - x (array[tuple]): data points\n",
    "        - y (array[int]): data labels\n",
    "        - nclass (int): number of classes\n",
    "    Returns:\n",
    "        - Plot\n",
    "    \"\"\"    \n",
    "    if fig == None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "     \n",
    "    # colors and labels\n",
    "    col = [\"red\",\"blue\",\"green\",\"yellow\"]\n",
    "    lab = [0,1,2,3]\n",
    "    \n",
    "    for i in range(nclass):\n",
    "        ax.scatter(x[y == lab[i], 0], x[y == lab[i], 1], c=col[i], s=20, edgecolor=\"k\")\n",
    "    ax.set_xlabel(\"$x_1$\")\n",
    "    ax.set_ylabel(\"$x_2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval_test = np.array(xval_test)\n",
    "yval_test = np.array(yval_test)\n",
    "yval_real = np.array(yval_real)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "plot_data(xval_test, yval_test, nclass, fig, axes[0])\n",
    "plot_data(xval_test, yval_real, nclass, fig, axes[1])\n",
    "\n",
    "axes[0].set_title(\"Single-qubit class. {} layers\".format(layers))\n",
    "axes[1].set_title(\"True test data\")\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.show()\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Total execution time: \", (t2-t0)/60,\" min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements and customization\n",
    "\n",
    "This tutorial just shows a simple classification example. It is constructed in a way that one can easily change the classification model and try more sophisticated problems comprising more classes. To do so, one should define the target states for >2 classes, i.e. include more vectors in the Bloch sphere.\n",
    "\n",
    "The single-qubit classifier circuit can also be modified to include higher dimensional data or to increase/reduce the number of parameters per layer.\n",
    "\n",
    "The cost function can also be improved. See for instance the weigthed fidelity cost function proposed in the main reference.\n",
    "\n",
    "Finally, the core of any variational algorithm is the minimization method. Tequila provides many methods besides the scipy ones. See the [optimizers tutorial](https://github.com/aspuru-guzik-group/tequila/blob/master/tutorials/Optimizer_Tutorial.ipynb) for more information.\n",
    "Notice also that the algorithm starts with a random initialization. It is well-known that random initialization in variational circuits leads to a barren-plateaus problem when computing the gradients. This problem can be avoided by providing a good initialization guess. \n",
    "\n",
    "Another possibility to play with expoloiting other Tequila modules is to use Phoenics for initial exploration and a gradient based optimizer with the best Phoenics results as starting point (see Phoenics documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqenv",
   "language": "python",
   "name": "tqenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
